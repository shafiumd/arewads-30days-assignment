{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise day 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Most Frequent Words:\n",
      "[('gutenberg', 5), ('of', 5), ('project', 4), ('the', 4), ('you', 4), ('is', 3), ('start', 3), ('and', 3), ('to', 3), ('ebooks', 2)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exercise 1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import statistics\n",
    "\n",
    "romeo_and_juliet_url = 'http://www.gutenberg.org/files/1112/1112.txt'\n",
    "response_romeo = requests.get(romeo_and_juliet_url)\n",
    "romeo_text = response_romeo.text\n",
    "\n",
    "words = romeo_text.split()\n",
    "word_frequencies = {}\n",
    "for word in words:\n",
    "    word = word.lower()\n",
    "    word = word.strip('.,!?\":;()[]{}')\n",
    "    if word.isalpha():\n",
    "        word_frequencies[word] = word_frequencies.get(word, 0) + 1\n",
    "\n",
    "most_frequent_words = sorted(word_frequencies.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"10 Most Frequent Words:\")\n",
    "print(most_frequent_words)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight Statistics (in metric units):\n",
      "min: 2.00\n",
      "max: 5.00\n",
      "mean: 3.22\n",
      "median: 3.00\n",
      "std_dev: 0.88\n",
      "\n",
      "Lifespan Statistics (in years):\n",
      "min: 8.00\n",
      "max: 18.00\n",
      "mean: 12.07\n",
      "median: 12.00\n",
      "std_dev: 1.83\n",
      "\n",
      "Frequency Table of Country and Breed of Cats:\n",
      "                         Country-Breed  Frequency\n",
      "0                   Egypt - Abyssinian          1\n",
      "1                      Greece - Aegean          1\n",
      "2     United States - American Bobtail          1\n",
      "3        United States - American Curl          1\n",
      "4   United States - American Shorthair          1\n",
      "..                                 ...        ...\n",
      "62                  Canada - Tonkinese          1\n",
      "63              United States - Toyger          1\n",
      "64             Turkey - Turkish Angora          1\n",
      "65                Turkey - Turkish Van          1\n",
      "66      United States - York Chocolate          1\n",
      "\n",
      "[67 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# exercise 2\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statistics import mean, median, stdev\n",
    "\n",
    "cats_api = 'https://api.thecatapi.com/v1/breeds'\n",
    "\n",
    "response = requests.get(cats_api)\n",
    "data = response.json()\n",
    "\n",
    "weights = []\n",
    "lifespans = []\n",
    "country_breed_freq = {}\n",
    "\n",
    "for cat in data:\n",
    "    weight = cat.get('weight', {}).get('metric', None)\n",
    "    lifespan = cat.get('life_span', None)\n",
    "    country = cat.get('origin', None)\n",
    "    breed = cat.get('name', None)\n",
    "\n",
    "    if weight and lifespan and country and breed:\n",
    "        weights.append(float(weight.split()[0])) \n",
    "        lifespans.append(float(lifespan.split()[0])) \n",
    "\n",
    "        key = f'{country} - {breed}'\n",
    "        country_breed_freq[key] = country_breed_freq.get(key, 0) + 1\n",
    "\n",
    "weight_stats = {\n",
    "    'min': min(weights),\n",
    "    'max': max(weights),\n",
    "    'mean': mean(weights),\n",
    "    'median': median(weights),\n",
    "    'std_dev': stdev(weights)\n",
    "}\n",
    "\n",
    "lifespan_stats = {\n",
    "    'min': min(lifespans),\n",
    "    'max': max(lifespans),\n",
    "    'mean': mean(lifespans),\n",
    "    'median': median(lifespans),\n",
    "    'std_dev': stdev(lifespans)\n",
    "}\n",
    "\n",
    "print(\"Weight Statistics (in metric units):\")\n",
    "for stat, value in weight_stats.items():\n",
    "    print(f\"{stat}: {value:.2f}\")\n",
    "\n",
    "print(\"\\nLifespan Statistics (in years):\")\n",
    "for stat, value in lifespan_stats.items():\n",
    "    print(f\"{stat}: {value:.2f}\")\n",
    "\n",
    "df = pd.DataFrame(list(country_breed_freq.items()), columns=['Country-Breed', 'Frequency'])\n",
    "print(\"\\nFrequency Table of Country and Breed of Cats:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exercise 3\n",
    "countries_api = 'https://restcountries.eu/rest/v2/all'\n",
    "response_countries = requests.get(countries_api)\n",
    "countries_data = response_countries.json()\n",
    "\n",
    "# Get the 10 largest countries\n",
    "largest_countries = sorted(countries_data, key=lambda x: x['area']['total'], reverse=True)[:10]\n",
    "print(\"Task 3 - 10 Largest Countries:\")\n",
    "for country in largest_countries:\n",
    "    print(country['name']['common'])\n",
    "print()\n",
    "\n",
    "# Get the 10 most spoken languages\n",
    "languages = [lang['name']['common'] for country in countries_data if 'languages' in country for lang in country['languages']]\n",
    "language_frequencies = {}\n",
    "for lang in languages:\n",
    "    language_frequencies[lang] = language_frequencies.get(lang, 0) + 1\n",
    "most_spoken_languages = sorted(language_frequencies.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "print(\"Task 3 - 10 Most Spoken Languages:\")\n",
    "print(most_spoken_languages)\n",
    "print()\n",
    "\n",
    "# Get the total number of languages in the countries API\n",
    "all_languages = set(lang['name']['common'] for country in countries_data if 'languages' in country for lang in country['languages'])\n",
    "total_languages = len(all_languages)\n",
    "print(f\"Task 3 - Total Number of Languages: {total_languages}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Dataset Titles:\n",
      "\n",
      "\n",
      "UCI Machine Learning Repository\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "       Datasets Contribute Dataset Donate New Link External About Us Who We Are Citation Metadata Contact Information           Login  404 Not Found Try these links instead Home Datasets  By using the UCI Machine Learning Repository,\n",
      "you acknowledge and accept the cookies and privacy practices used by the UCI Machine Learning Repository. Accept Read Policy  The Project About Us CML National Science Foundation Navigation Home View Datasets Donate a Dataset Logistics Contact Privacy Notice Feature Request or Bug Report  Browse Datasets Donate a Dataset Link an external Dataset  Who We Are Citation Metadata Contact Information   Login\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# exercise 4\n",
    "uci_url = 'https://archive.ics.uci.edu/ml/datasets.php'\n",
    "response_uci = requests.get(uci_url)\n",
    "soup = BeautifulSoup(response_uci.text, 'html.parser')\n",
    "uci_content = soup.get_text()\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "if soup:\n",
    "    print(\"List of Dataset Titles:\")\n",
    "    for title in soup:\n",
    "        print(title.text.strip())\n",
    "else:\n",
    "        print(\"No dataset titles found on the page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
